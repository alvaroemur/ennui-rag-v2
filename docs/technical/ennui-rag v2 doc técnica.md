# ennui-rag Â· DocumentaciÃ³n TÃ©cnica Completa

## ğŸ“‹ Resumen Ejecutivo

**ennui-rag** es un sistema RAG (Retrieval-Augmented Generation) avanzado diseÃ±ado para la indexaciÃ³n, enriquecimiento y bÃºsqueda inteligente de documentos almacenados en Google Drive. El sistema implementa un pipeline completo que va desde la extracciÃ³n de metadatos hasta la generaciÃ³n de respuestas contextualizadas mediante IA, con persistencia robusta en mÃºltiples bases de datos.

### ğŸ¯ PropÃ³sito Principal
- **IndexaciÃ³n Inteligente**: Escaneo recursivo de carpetas de Google Drive con soporte para Shortcuts y Shared Drives
- **Enriquecimiento de Datos**: ExtracciÃ³n de contenido textual, generaciÃ³n de embeddings y metadatos enriquecidos
- **BÃºsqueda SemÃ¡ntica**: Sistema de bÃºsqueda hÃ­brida que combina bÃºsqueda lexical y semÃ¡ntica
- **Persistencia Idempotente**: Almacenamiento confiable en Supabase y MongoDB con prevenciÃ³n de duplicados

### ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Google Drive  â”‚â”€â”€â”€â–¶â”‚   IndexaciÃ³n     â”‚â”€â”€â”€â–¶â”‚   Persistencia  â”‚
â”‚   (Fuente)      â”‚    â”‚   & Traversal    â”‚    â”‚   (Supabase/    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    MongoDB)      â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interfaz      â”‚â—€â”€â”€â”€â”‚   BÃºsqueda       â”‚â—€â”€â”€â”€â”‚   Enriquecimientoâ”‚
â”‚   Streamlit     â”‚    â”‚   & Reranking    â”‚    â”‚   & Embeddings  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ MÃ³dulos y Componentes Principales

### 1. **ConfiguraciÃ³n y Settings** (`src/ennui_rag/settings.py`)

#### Clase `Env`
```python
class Env(BaseSettings):
    OPENAI_API_KEY: str | None = None
    SB_SECRET: str | None = None
    SB_PASSWORD: str | None = None
    SUPABASE_REF: str | None = None
    SUPABASE_URL: str | None = None
    SUPABASE_KEY: str | None = None
    POSTGRES_DSN: str | None = None
    SUPABASE_CLIENT: object | None = None
    MONGO_URI: str | None = None
    MONGO_CLIENT: object | None = None
```

**DescripciÃ³n Enriquecida**: La clase `Env` actÃºa como el centro de configuraciÃ³n del sistema, implementando un patrÃ³n de configuraciÃ³n centralizada que gestiona credenciales de mÃºltiples servicios (OpenAI, Supabase, MongoDB) de manera segura. Utiliza Pydantic para validaciÃ³n automÃ¡tica de tipos y carga configuraciÃ³n desde variables de entorno y archivos YAML, garantizando flexibilidad en diferentes entornos de despliegue.

#### Funciones de ConfiguraciÃ³n

**`get_config(env: str = "dev") -> Tuple[Env, Dict[str, Any]]`**
- **PropÃ³sito**: Inicializa la configuraciÃ³n completa del sistema
- **ParÃ¡metros**: `env` - Entorno de ejecuciÃ³n (dev/prod)
- **Retorna**: Tupla con variables de entorno validadas y configuraciÃ³n YAML
- **DescripciÃ³n Enriquecida**: Esta funciÃ³n implementa el patrÃ³n Factory para la configuraciÃ³n, cargando automÃ¡ticamente credenciales, inicializando clientes de base de datos y mezclando configuraciones base con especÃ­ficas del entorno. Incluye manejo robusto de errores y logging detallado para facilitar el debugging.

**`_init_supabase(env_vars: Env)`**
- **PropÃ³sito**: Configura e inicializa el cliente de Supabase
- **DescripciÃ³n Enriquecida**: Implementa la inicializaciÃ³n lazy del cliente Supabase, construyendo automÃ¡ticamente URLs y validando credenciales. Incluye fallback graceful si las credenciales no estÃ¡n disponibles.

**`_init_postgres(env_vars: Env)`**
- **PropÃ³sito**: Configura la cadena de conexiÃ³n PostgreSQL
- **DescripciÃ³n Enriquecida**: Construye dinÃ¡micamente el DSN de PostgreSQL usando el ref de Supabase y la contraseÃ±a, permitiendo conexiÃ³n directa a la base de datos subyacente.

**`_init_mongo(env_vars: Env)`**
- **PropÃ³sito**: Inicializa el cliente MongoDB opcional
- **DescripciÃ³n Enriquecida**: Configura MongoDB como almacÃ©n secundario, implementando el patrÃ³n de persistencia dual para mayor robustez y flexibilidad.

---

### 2. **Pipeline de IndexaciÃ³n** (`src/ennui_rag/pipelines/`)

#### `index_pipeline.py`

**`run_index(env: str = "dev", folder_id: Optional[str] = None, max_items: Optional[int] = None, stores: Optional[List] = None, save_csv: bool = True, always_persist: bool = True) -> pd.DataFrame`**

- **PropÃ³sito**: Pipeline principal de indexaciÃ³n de Google Drive
- **ParÃ¡metros**:
  - `env`: Entorno de configuraciÃ³n
  - `folder_id`: ID de la carpeta raÃ­z a indexar
  - `max_items`: LÃ­mite de elementos a procesar
  - `stores`: Lista de almacenes de persistencia
  - `save_csv`: Si guardar el catÃ¡logo en CSV
  - `always_persist`: Si persistir automÃ¡ticamente en BD
- **Retorna**: DataFrame con metadatos indexados
- **DescripciÃ³n Enriquecida**: Esta funciÃ³n implementa el patrÃ³n Pipeline para el procesamiento de datos, orquestando la indexaciÃ³n completa desde la extracciÃ³n de metadatos hasta la persistencia. Incluye manejo de errores robusto, logging detallado y soporte para procesamiento por lotes. La funciÃ³n es idempotente, permitiendo re-ejecuciones seguras sin duplicar datos.

#### `project_pipeline.py`

**`select_project(folder_id: str) -> dict`**
- **PropÃ³sito**: Selecciona y configura un proyecto activo
- **ParÃ¡metros**: `folder_id` - ID de la carpeta del proyecto
- **Retorna**: Diccionario con metadatos del proyecto
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n State para la gestiÃ³n de proyectos, creando y actualizando metadatos de sesiÃ³n. Mantiene un registro de proyectos recientes y facilita la navegaciÃ³n entre diferentes proyectos.

**`ensure_catalog(project_id: str, force: bool = False, max_items: int | None = None, persist: bool = True) -> str`**
- **PropÃ³sito**: Asegura que existe un catÃ¡logo para el proyecto
- **ParÃ¡metros**:
  - `project_id`: ID del proyecto
  - `force`: Forzar re-indexaciÃ³n
  - `max_items`: LÃ­mite de elementos
  - `persist`: Si persistir en BD
- **Retorna**: Ruta al archivo CSV del catÃ¡logo
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Lazy Loading para catÃ¡logos, reutilizando catÃ¡logos existentes cuando es posible y generando nuevos solo cuando es necesario. Incluye validaciÃ³n de integridad y metadatos de sesiÃ³n.

**`project_status(project_id: str) -> dict`**
- **PropÃ³sito**: Obtiene el estado actual del proyecto
- **Retorna**: Diccionario con estadÃ­sticas del proyecto
- **DescripciÃ³n Enriquecida**: Proporciona una vista consolidada del estado del proyecto, incluyendo conteos de archivos, fechas de Ãºltima modificaciÃ³n y estado de las bases de datos. Implementa el patrÃ³n Observer para monitoreo en tiempo real.

**`list_recent_projects(limit: int = 10) -> list[dict]`**
- **PropÃ³sito**: Lista proyectos recientes ordenados por fecha
- **DescripciÃ³n Enriquecida**: Implementa un sistema de historial de proyectos con ordenamiento temporal, facilitando la navegaciÃ³n y el acceso rÃ¡pido a proyectos frecuentemente utilizados.

---

### 3. **Sistema de IndexaciÃ³n** (`src/ennui_rag/indexing/`)

#### `build.py`

**`build_catalog_dataframe(root_id: str, max_items: Optional[int] = None) -> pd.DataFrame`**
- **PropÃ³sito**: Construye el DataFrame principal del catÃ¡logo
- **ParÃ¡metros**:
  - `root_id`: ID de la carpeta raÃ­z
  - `max_items`: LÃ­mite de elementos a procesar
- **Retorna**: DataFrame con metadatos de archivos
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Builder para la construcciÃ³n de catÃ¡logos, orquestando el recorrido del Ã¡rbol de directorios y la normalizaciÃ³n de datos. Incluye optimizaciones de memoria y procesamiento por lotes.

**`save_catalog_csv(df: pd.DataFrame, path: str = CSV_PATH) -> None`**
- **PropÃ³sito**: Guarda el catÃ¡logo en formato CSV
- **DescripciÃ³n Enriquecida**: Implementa persistencia local eficiente con manejo de directorios y codificaciÃ³n UTF-8, asegurando compatibilidad con herramientas externas.

#### `traversal.py`

**`walk_drive_tree(svc, root_id: str, max_items: Optional[int] = None) -> List[Dict]`**
- **PropÃ³sito**: Recorre recursivamente el Ã¡rbol de Google Drive
- **ParÃ¡metros**:
  - `svc`: Servicio de Google Drive
  - `root_id`: ID de la carpeta raÃ­z
  - `max_items`: LÃ­mite de elementos
- **Retorna**: Lista de diccionarios con metadatos de archivos
- **DescripciÃ³n Enriquecida**: Implementa un algoritmo DFS (Depth-First Search) optimizado para Google Drive, con soporte completo para Shortcuts y Shared Drives. Incluye manejo de paginaciÃ³n, logging de progreso y control de lÃ­mites. El algoritmo es resiliente a errores de red y implementa retry automÃ¡tico.

#### `normalize.py`

**`normalize_df_to_records(df: pd.DataFrame, project_id: Optional[str] = None, session_id: Optional[str] = None, root_folder_id: Optional[str] = None) -> List[Dict]`**
- **PropÃ³sito**: Normaliza el DataFrame a registros para persistencia
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Adapter para la normalizaciÃ³n de datos, convirtiendo el formato interno del DataFrame a un formato estÃ¡ndar para persistencia. Incluye validaciÃ³n de tipos, limpieza de datos y enriquecimiento de metadatos.

---

### 4. **Sistema de Persistencia** (`src/ennui_rag/persistence/`)

#### `base.py`

**Clase `CatalogStore` (ABC)**
```python
class CatalogStore(ABC):
    @abstractmethod
    def prepare(self) -> None: ...
    @abstractmethod
    def upsert(self, records: Iterable[Dict[str, Any]], batch_size: int = 500) -> int: ...
```

**DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Strategy para la persistencia, definiendo una interfaz comÃºn para diferentes tipos de almacenes. Permite la extensiÃ³n fÃ¡cil del sistema con nuevos tipos de bases de datos sin modificar el cÃ³digo cliente.

**`persist_catalog_df(df: pd.DataFrame, stores: List[CatalogStore], batch_size: int = 500, deduplicate: bool = True, project_id: Optional[str] = None, session_id: Optional[str] = None, root_folder_id: Optional[str] = None) -> Dict[str, int]`**

- **PropÃ³sito**: Persiste el catÃ¡logo en mÃºltiples almacenes
- **ParÃ¡metros**:
  - `df`: DataFrame a persistir
  - `stores`: Lista de almacenes de destino
  - `batch_size`: TamaÃ±o de lote para procesamiento
  - `deduplicate`: Si eliminar duplicados
  - `project_id`, `session_id`, `root_folder_id`: Metadatos contextuales
- **Retorna**: Diccionario con conteos de registros procesados por almacÃ©n
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Command para operaciones de persistencia, permitiendo la ejecuciÃ³n de operaciones complejas de manera atÃ³mica. Incluye deduplicaciÃ³n inteligente, sanitizaciÃ³n de datos y manejo de errores robusto.

#### `supabase.py`

**Clase `SupabaseStore`**
```python
class SupabaseStore(CatalogStore):
    def __init__(self, client: Client, table: str = "catalog_drive", on_conflict: str = "project_id,file_id,drive_id")
    def prepare(self) -> None
    def upsert(self, records: Iterable[Dict[str, Any]], batch_size: int = 500) -> int
    def select_all(self, limit: Optional[int] = None) -> List[Dict[str, Any]]
    def select_by_project(self, project_id: str, limit: Optional[int] = None) -> List[Dict[str, Any]]
    def select_by_ids(self, file_ids: List[str], drive_id: Optional[str] = None) -> List[Dict[str, Any]]
    def count(self) -> int
    def count_by_project(self, project_id: str) -> int
```

**DescripciÃ³n Enriquecida**: Implementa un almacÃ©n de datos robusto para Supabase, con soporte completo para operaciones CRUD y consultas complejas. Incluye manejo de conflictos de clave primaria, deduplicaciÃ³n intra-lote y logging detallado. La implementaciÃ³n es altamente optimizada para grandes volÃºmenes de datos.

---

### 5. **Sistema de Enriquecimiento** (`src/ennui_rag/enrichment/`)

#### `extractors.py`

**Clase `SnippetExtractor` (ABC)**
```python
class SnippetExtractor(ABC):
    name: str = "base"
    def matches(self, row: FileRow) -> bool
    def extract(self, drive: Any, row: FileRow, *, max_chars: int, head_max_lines: int, head_max_bytes: int, bytes_chunk: int) -> SnippetResult
```

**DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Strategy para la extracciÃ³n de contenido, permitiendo diferentes estrategias segÃºn el tipo de archivo. Cada extractor estÃ¡ optimizado para tipos especÃ­ficos de archivos y utiliza las APIs mÃ¡s apropiadas para cada caso.

**Extractores Especializados**:

- **`GDocExtractor`**: Extrae contenido completo de Google Docs usando la API de exportaciÃ³n
- **`SheetCsvExtractor`**: Procesa Google Sheets y archivos CSV con muestreo inteligente
- **`ExcelExtractor`**: Maneja archivos Excel con anÃ¡lisis de estructura y contenido
- **`TextLikeExtractor`**: Procesa archivos de texto plano con mÃºltiples formatos

**`get_snippet(drive: Any, row: FileRow, *, max_chars: int = 1200, head_max_lines: int = HEAD_MAX_LINES_DEFAULT, head_max_bytes: int = HEAD_MAX_BYTES_DEFAULT, bytes_chunk: int = BYTES_CHUNK_DEFAULT, extractors: Optional[List[SnippetExtractor]] = None) -> SnippetResult`**

- **PropÃ³sito**: Orquesta la extracciÃ³n de contenido usando mÃºltiples extractores
- **DescripciÃ³n Enriquecida**: Implementa el patrÃ³n Chain of Responsibility para la extracciÃ³n de contenido, probando extractores en orden de prioridad hasta encontrar uno que funcione. Incluye manejo de errores graceful y fallback automÃ¡tico.

---

### 6. **Sistema de BÃºsqueda** (`src/ennui_rag/search/`)

#### `search.py`

**`search_llm(query: str, project_id: str, *, data_dir: Path | None = None, k: int = 40, n: int = 12, kind: Optional[str] = None, use_embeddings: bool = False, q_vec = None, by_path: str | None = None, by_mime: str | None = None, modified_from: str | None = None, modified_to: str | None = None, as_answer: bool = False, answer_k: int = 5, debug: bool = False, return_candidates: bool = False) -> pd.DataFrame | dict`**

- **PropÃ³sito**: Sistema de bÃºsqueda hÃ­brida con reranking por LLM
- **ParÃ¡metros**:
  - `query`: Consulta de bÃºsqueda
  - `project_id`: ID del proyecto a buscar
  - `k`: NÃºmero de candidatos a recuperar
  - `n`: NÃºmero de resultados finales
  - `use_embeddings`: Si usar bÃºsqueda semÃ¡ntica
  - `as_answer`: Si devolver respuesta generada
- **Retorna**: DataFrame con resultados o diccionario con respuesta
- **DescripciÃ³n Enriquecida**: Implementa un sistema de bÃºsqueda hÃ­brida que combina bÃºsqueda lexical tradicional con bÃºsqueda semÃ¡ntica basada en embeddings. Incluye reranking inteligente usando LLM, filtros avanzados y generaciÃ³n de respuestas contextualizadas. El sistema es altamente configurable y optimizado para diferentes casos de uso.

---

### 7. **Interfaz de Usuario** (`src/ennui_rag/app/`)

#### `ui_streamlit.py`

**Funciones Principales**:
- **`main()`**: FunciÃ³n principal de la aplicaciÃ³n Streamlit
- **`render_sidebar()`**: Renderiza la barra lateral con navegaciÃ³n
- **`render_main_content()`**: Renderiza el contenido principal segÃºn la secciÃ³n activa

**DescripciÃ³n Enriquecida**: Implementa una interfaz de usuario moderna y responsiva usando Streamlit, con navegaciÃ³n por pestaÃ±as y componentes modulares. La interfaz incluye paneles especializados para indexaciÃ³n, enriquecimiento, bÃºsqueda y gestiÃ³n de estado. Implementa el patrÃ³n MVC (Model-View-Controller) para separaciÃ³n clara de responsabilidades.

---

### 8. **Entrada/Salida** (`src/ennui_rag/io/`)

#### `drive_io.py`

**`get_drive_service()`**
- **PropÃ³sito**: Inicializa el servicio de Google Drive
- **DescripciÃ³n Enriquecida**: Configura la autenticaciÃ³n OAuth2 con Google Drive usando credenciales de service account, implementando el patrÃ³n Singleton para reutilizaciÃ³n eficiente de conexiones.

**`get_file_meta(service, file_id: str) -> Dict`**
- **PropÃ³sito**: Obtiene metadatos de un archivo especÃ­fico
- **DescripciÃ³n Enriquecida**: Implementa retry automÃ¡tico con backoff exponencial para manejar limitaciones de rate de la API de Google Drive.

**`list_children(service, folder_id: str, page_token: Optional[str] = None) -> Tuple[List[Dict], Optional[str]]`**
- **PropÃ³sito**: Lista archivos hijos de una carpeta con paginaciÃ³n
- **DescripciÃ³n Enriquecida**: Implementa paginaciÃ³n eficiente para manejar carpetas con muchos archivos, incluyendo soporte para Shared Drives y filtros de trashed files.

---

## ğŸ”„ Flujos de Trabajo Principales

### 1. **Flujo de IndexaciÃ³n**
```
Google Drive â†’ Traversal â†’ NormalizaciÃ³n â†’ Persistencia â†’ CSV Local
     â†“              â†“            â†“             â†“
  Metadatos    Estructura    ValidaciÃ³n    MÃºltiples BD
```

### 2. **Flujo de Enriquecimiento**
```
CSV Local â†’ ExtracciÃ³n â†’ LLM Processing â†’ Embeddings â†’ Persistencia
    â†“           â†“             â†“              â†“
  Archivos   Contenido    Descripciones   Vectores
```

### 3. **Flujo de BÃºsqueda**
```
Query â†’ Retrieval â†’ Reranking â†’ Answer Generation
  â†“        â†“           â†“              â†“
Usuario  Candidatos  LLM Score    Respuesta
```

---

## ğŸ› ï¸ Patrones de DiseÃ±o Implementados

1. **Factory Pattern**: ConfiguraciÃ³n y creaciÃ³n de clientes de BD
2. **Strategy Pattern**: Extractores de contenido y almacenes de persistencia
3. **Observer Pattern**: Monitoreo de estado de proyectos
4. **Command Pattern**: Operaciones de persistencia
5. **Chain of Responsibility**: ExtracciÃ³n de contenido
6. **Singleton Pattern**: Servicios de Google Drive
7. **Builder Pattern**: ConstrucciÃ³n de catÃ¡logos
8. **Adapter Pattern**: NormalizaciÃ³n de datos

---

## ğŸ“Š MÃ©tricas y Monitoreo

El sistema incluye mÃ©tricas detalladas para:
- **IndexaciÃ³n**: Elementos procesados, tiempo de ejecuciÃ³n, errores
- **Persistencia**: Registros insertados/actualizados por almacÃ©n
- **BÃºsqueda**: Tiempo de respuesta, precisiÃ³n de resultados
- **Enriquecimiento**: Archivos procesados, calidad de extracciÃ³n

---

## ğŸš€ CaracterÃ­sticas Avanzadas

1. **Idempotencia**: Operaciones seguras para re-ejecuciÃ³n
2. **DeduplicaciÃ³n**: PrevenciÃ³n de registros duplicados
3. **Retry AutomÃ¡tico**: Manejo robusto de errores de red
4. **Procesamiento por Lotes**: OptimizaciÃ³n de memoria y rendimiento
5. **Filtros Avanzados**: BÃºsqueda por tipo, fecha, ruta, MIME
6. **BÃºsqueda HÃ­brida**: CombinaciÃ³n de lexical y semÃ¡ntica
7. **Interfaz Modular**: Componentes reutilizables y extensibles

---

## ğŸ“ˆ Escalabilidad y Rendimiento

- **Procesamiento AsÃ­ncrono**: Para operaciones de I/O intensivas
- **CachÃ© Inteligente**: ReutilizaciÃ³n de catÃ¡logos existentes
- **PaginaciÃ³n Eficiente**: Manejo de grandes volÃºmenes de datos
- **CompresiÃ³n**: OptimizaciÃ³n de almacenamiento
- **Ãndices Optimizados**: Consultas rÃ¡pidas en bases de datos

---

*Documento generado automÃ¡ticamente con enriquecimiento de IA - ennui-rag v0.1.0*
